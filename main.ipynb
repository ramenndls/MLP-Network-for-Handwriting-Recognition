{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGP5woydMEMa",
        "outputId": "36ff4322-49f5-47b4-e06c-e7fc75a24ee2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/sorki/python-mnist\n",
        "!./python-mnist/bin/mnist_get_data.sh\n",
        "!pip3 install emnist\n",
        "from emnist import extract_training_samples"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'python-mnist'...\n",
            "remote: Enumerating objects: 246, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 246 (delta 1), reused 2 (delta 0), pack-reused 240 (from 1)\u001b[K\n",
            "Receiving objects: 100% (246/246), 47.14 KiB | 1.88 MiB/s, done.\n",
            "Resolving deltas: 100% (119/119), done.\n",
            "--2025-02-18 11:57:22--  http://yann.lecun.com/exdb/mnist/\n",
            "Resolving yann.lecun.com (yann.lecun.com)... 15.204.224.156\n",
            "Connecting to yann.lecun.com (yann.lecun.com)|15.204.224.156|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 756 [text/html]\n",
            "Saving to: ‘data/index.html.tmp’\n",
            "\n",
            "index.html.tmp      100%[===================>]     756  --.-KB/s    in 0s      \n",
            "\n",
            "2025-02-18 11:57:22 (75.6 MB/s) - ‘data/index.html.tmp’ saved [756/756]\n",
            "\n",
            "Loading robots.txt; please ignore errors.\n",
            "--2025-02-18 11:57:22--  http://yann.lecun.com/robots.txt\n",
            "Reusing existing connection to yann.lecun.com:80.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2025-02-18 11:57:22 ERROR 404: Not Found.\n",
            "\n",
            "Removing data/index.html.tmp since it should be rejected.\n",
            "\n",
            "--2025-02-18 11:57:22--  http://yann.lecun.com/exdb/mnist/?C=N;O=D\n",
            "Reusing existing connection to yann.lecun.com:80.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 756 [text/html]\n",
            "Saving to: ‘data/index.html?C=N;O=D.tmp’\n",
            "\n",
            "index.html?C=N;O=D. 100%[===================>]     756  --.-KB/s    in 0s      \n",
            "\n",
            "2025-02-18 11:57:22 (71.9 MB/s) - ‘data/index.html?C=N;O=D.tmp’ saved [756/756]\n",
            "\n",
            "Removing data/index.html?C=N;O=D.tmp since it should be rejected.\n",
            "\n",
            "--2025-02-18 11:57:22--  http://yann.lecun.com/exdb/mnist/?C=M;O=A\n",
            "Reusing existing connection to yann.lecun.com:80.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 756 [text/html]\n",
            "Saving to: ‘data/index.html?C=M;O=A.tmp’\n",
            "\n",
            "index.html?C=M;O=A. 100%[===================>]     756  --.-KB/s    in 0s      \n",
            "\n",
            "2025-02-18 11:57:22 (70.3 MB/s) - ‘data/index.html?C=M;O=A.tmp’ saved [756/756]\n",
            "\n",
            "Removing data/index.html?C=M;O=A.tmp since it should be rejected.\n",
            "\n",
            "--2025-02-18 11:57:22--  http://yann.lecun.com/exdb/mnist/?C=S;O=A\n",
            "Reusing existing connection to yann.lecun.com:80.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 756 [text/html]\n",
            "Saving to: ‘data/index.html?C=S;O=A.tmp’\n",
            "\n",
            "index.html?C=S;O=A. 100%[===================>]     756  --.-KB/s    in 0s      \n",
            "\n",
            "2025-02-18 11:57:22 (79.9 MB/s) - ‘data/index.html?C=S;O=A.tmp’ saved [756/756]\n",
            "\n",
            "Removing data/index.html?C=S;O=A.tmp since it should be rejected.\n",
            "\n",
            "--2025-02-18 11:57:22--  http://yann.lecun.com/exdb/mnist/?C=D;O=A\n",
            "Reusing existing connection to yann.lecun.com:80.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 756 [text/html]\n",
            "Saving to: ‘data/index.html?C=D;O=A.tmp’\n",
            "\n",
            "index.html?C=D;O=A. 100%[===================>]     756  --.-KB/s    in 0s      \n",
            "\n",
            "2025-02-18 11:57:23 (85.1 MB/s) - ‘data/index.html?C=D;O=A.tmp’ saved [756/756]\n",
            "\n",
            "Removing data/index.html?C=D;O=A.tmp since it should be rejected.\n",
            "\n",
            "--2025-02-18 11:57:23--  http://yann.lecun.com/exdb/\n",
            "Reusing existing connection to yann.lecun.com:80.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2077 (2.0K) [text/html]\n",
            "Saving to: ‘data/index.html.tmp’\n",
            "\n",
            "index.html.tmp      100%[===================>]   2.03K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-02-18 11:57:23 (221 MB/s) - ‘data/index.html.tmp’ saved [2077/2077]\n",
            "\n",
            "Removing data/index.html.tmp since it should be rejected.\n",
            "\n",
            "FINISHED --2025-02-18 11:57:23--\n",
            "Total wall clock time: 0.2s\n",
            "Downloaded: 6 files, 5.7K in 0s (99.3 MB/s)\n",
            "/content/data /content\n",
            "gzip: *.gz: No such file or directory\n",
            "/content\n",
            "Collecting emnist\n",
            "  Downloading emnist-0.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from emnist) (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from emnist) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from emnist) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->emnist) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->emnist) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->emnist) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->emnist) (2025.1.31)\n",
            "Downloading emnist-0.0-py3-none-any.whl (7.3 kB)\n",
            "Installing collected packages: emnist\n",
            "Successfully installed emnist-0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDj9tyEAMVn5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "5159207f-61a5-4eb9-bbd3-a63668e9adda"
      },
      "source": [
        "# X is the images and y is the labels\n",
        "X, y = extract_training_samples('letters')\n",
        "X = X / 255.\n",
        "\n",
        "# First 60000 instances as training and the next 10000 as testing\n",
        "X_train, X_test = X[:60000], X[60000:70000]\n",
        "y_train, y_test = y[:60000], y[60000:70000]\n",
        "\n",
        "X_train = X_train.reshape(60000,784)\n",
        "X_test = X_test.reshape(10000,784)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "BadZipFile",
          "evalue": "File is not a zip file",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-fc27bf5e78c0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# X is the images and y is the labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_training_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'letters'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# First 60000 instances as training and the next 10000 as testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/emnist/__init__.py\u001b[0m in \u001b[0;36mextract_training_samples\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \"\"\"Extract the training samples for a given dataset as a pair of numpy arrays, (images, labels). The dataset must be\n\u001b[1;32m    208\u001b[0m     one of those listed by list_datasets(), e.g. 'digits' or 'mnist'.\"\"\"\n\u001b[0;32m--> 209\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mextract_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/emnist/__init__.py\u001b[0m in \u001b[0;36mextract_samples\u001b[0;34m(dataset, usage)\u001b[0m\n\u001b[1;32m    197\u001b[0m     \"\"\"Extract the samples for a given dataset and usage as a pair of numpy arrays, (images, labels). The dataset must\n\u001b[1;32m    198\u001b[0m     be one of those listed by list_datasets(), e.g. 'digits' or 'mnist'. Usage should be either 'train' or 'test'.\"\"\"\n\u001b[0;32m--> 199\u001b[0;31m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'images'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'labels'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/emnist/__init__.py\u001b[0m in \u001b[0;36mextract_data\u001b[0;34m(dataset, usage, component)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0mcache_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_cached_data_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0mzip_internal_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZIP_PATH_TEMPLATE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0musage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0mcompressed_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_internal_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompressed_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[1;32m   1311\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1312\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1313\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_RealGetContents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1314\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m                 \u001b[0;31m# set the modified flag so central directory gets written\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/zipfile.py\u001b[0m in \u001b[0;36m_RealGetContents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1378\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mendrec\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1380\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1381\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBadZipFile\u001b[0m: File is not a zip file"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWcb4sxAP2lT"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img_index = 14440 #value determines image shown\n",
        "img = X_train[img_index]\n",
        "print(\"Image Label: \" + str(chr(y_train[img_index]+96)))\n",
        "plt.imshow(img.reshape((28,28)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "#MLP, 6 layers, 300 neurons, iterates 50 times\n",
        "mlp2 = MLPClassifier(hidden_layer_sizes=(300,300,300,300,300,300,), max_iter=75, alpha=1e-4,\n",
        "                    solver='sgd', verbose=10, tol=1e-4, random_state=1,\n",
        "                    learning_rate_init=.1)\n",
        "mlp2.fit(X_train, y_train)\n",
        "print(\"Training set score: %f\" % mlp2.score(X_train, y_train))\n",
        "print(\"Test set score: %f\" % mlp2.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "IWotF3R_pFMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ux7zg-iYAhv"
      },
      "source": [
        "y_pred = mlp2.predict(X_test) #list of predicted values\n",
        "\n",
        "from sklearn.metrics import confusion_matrix #errors\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.matshow(cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGNJFFZmfS4I"
      },
      "source": [
        "#possible confused letters\n",
        "predicted_letter = 'l'\n",
        "actual_letter = 'i'\n",
        "\n",
        "mistake_list = []\n",
        "for i in range(len(y_test)):\n",
        "  if (y_test[i] == (ord(actual_letter) - 96) and y_pred[i] == (ord(predicted_letter) - 96)):\n",
        "    mistake_list.append(i)\n",
        "print(\"There were \" + str(len(mistake_list)) + \" times that the letter \" + actual_letter + \" was predicted to be the letter \" + predicted_letter + \".\")\n",
        "\n",
        "mistake_to_show = 4 #mistake number\n",
        "\n",
        "if (len(mistake_list)> mistake_to_show): #shows numbered mistake\n",
        "  img = X_test[mistake_list[mistake_to_show]]\n",
        "  plt.imshow(img.reshape((28,28)))\n",
        "else:\n",
        "  print(\"Couldn't show mistake number \" + str(mistake_to_show + 1) + \" because there were only \" + str(len(mistake_list)) + \" mistakes to show!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bs1-wuqGHYRm"
      },
      "source": [
        "!git clone https://github.com/ramenndls/my_writing_mod.git #all images are uploaded in this repository, and all have been color inverted\n",
        "!git pull\n",
        "!ls my_writing_mod\n",
        "!cd /content/my_writing_mod\n",
        "!pwd\n",
        "\n",
        "import os\n",
        "path, dirs, files = next(os.walk(\"/content/my_writing_mod/\"))\n",
        "files.sort()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0hPrlEvW5ZY"
      },
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "handwritten_words = [] #adds all files to a list\n",
        "for i in range(len(files)):\n",
        "  img = cv2.imread(\"/content/my_writing_mod/\"+files[i],cv2.IMREAD_GRAYSCALE)\n",
        "  handwritten_words.append(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TPLm8eYoq38"
      },
      "source": [
        "import numpy\n",
        "import cv2\n",
        "\n",
        "words = \"\"\n",
        "for letter in handwritten_words:\n",
        "    letter = cv2.resize(letter, (28,28), interpolation = cv2.INTER_CUBIC)\n",
        "    single_item_array = (numpy.array(letter)).reshape(1,784)\n",
        "    prediction = mlp2.predict(single_item_array)\n",
        "    words = words + str(chr(prediction[0]+96))\n",
        "\n",
        "print(\"Conversion complete!\")\n",
        "print(words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8BGJtQRq1xi"
      },
      "source": [
        "import numpy\n",
        "\n",
        "#checks to see if the image is just a blank space\n",
        "total_pixel_value = 0\n",
        "for j in range(28):\n",
        "  for k in range(28):\n",
        "    total_pixel_value += letter[j,k]\n",
        "if total_pixel_value < 20:\n",
        "  words = words + \" \"\n",
        "else:         #if it NOT a blank, it actually runs the prediction algorithm on it\n",
        "  single_item_array = (numpy.array(letter)).reshape(1,784)\n",
        "  prediction = mlp2.predict(single_item_array)\n",
        "  words = words + str(chr(prediction[0]+96))\n",
        "\n",
        "print(\"Conversion complete!\")\n",
        "print(words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQ1SqowzKeHG"
      },
      "source": [
        "processed_words = []\n",
        "\n",
        "for img in handwritten_words:\n",
        "  #Apply Gaussian blur filter\n",
        "  img = cv2.GaussianBlur(img, (7,7), 0)\n",
        "\n",
        "  #Extract the Region of Interest in the image and center in square\n",
        "  points = cv2.findNonZero(img)\n",
        "  x, y, w, h = cv2.boundingRect(points)\n",
        "  if (w > 0 and h > 0):\n",
        "    if w > h:\n",
        "      y = y - (w-h)//2\n",
        "      img = img[y:y+w, x:x+w]\n",
        "    else:\n",
        "      x = x - (h-w)//2\n",
        "      img = img[y:y+h, x:x+h]\n",
        "\n",
        "  #Resize and resample to be 28 x 28 pixels\n",
        "  img = cv2.resize(img, (28,28), interpolation = cv2.INTER_CUBIC)\n",
        "\n",
        "  #Normalize pixels and reshape before adding to the new story array\n",
        "  img = img/255\n",
        "  img = img.reshape((28,28))\n",
        "  processed_words.append(img)\n",
        "\n",
        "print(\"Processed the scanned images.\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(processed_words[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFH4kBA9ar-O"
      },
      "source": [
        "import numpy\n",
        "\n",
        "typed_story = \"\"\n",
        "for letter in processed_words:\n",
        "  #this bit of code checks to see if the image is just a blank space by looking at the color of all the pixels summed\n",
        "  total_pixel_value = 0\n",
        "  for j in range(28):\n",
        "    for k in range(28):\n",
        "      total_pixel_value += letter[j,k]\n",
        "  if total_pixel_value < 20:\n",
        "    typed_story = typed_story + \" \"\n",
        "  else:         #if it NOT a blank, it actually runs the prediction algorithm on it\n",
        "    single_item_array = (numpy.array(letter)).reshape(1,784)\n",
        "    prediction = mlp2.predict(single_item_array)\n",
        "    typed_story = typed_story + str(chr(prediction[0]+96))\n",
        "\n",
        "true_value = 'abklmnopqrstcuvwxyzdefghij'\n",
        "print(\"Conversion complete!\"'\\n') #true value = abklmnopqrstcuvwxyzdefghij\n",
        "print('conversion:', typed_story)\n",
        "print('true value:', true_value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from difflib import SequenceMatcher\n",
        "#compares both strings and outputs a % indicating how accurate the converted value is\n",
        "s = SequenceMatcher(None, typed_story, true_value)\n",
        "print('percentage similarity:', s.ratio())"
      ],
      "metadata": {
        "id": "nwUV1tevw93I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}